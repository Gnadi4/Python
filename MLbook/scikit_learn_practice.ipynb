{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd09a55372cc88767ffbdea7cf0ff1dfc68c4728005d93913fd5c137d9dbb8970d1",
   "display_name": "Python 3.7.10 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.24.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "#iris.data는 Iris 데이터 세트에서 피처 만으로 된 데이터를 numpy로 가지고 있음\n",
    "iris_data = iris.data\n",
    "\n",
    "#iris.target은 붓꽃 데이터 세트에서 레이블 데이터를 Numpy로 가지고 있음\n",
    "iris_label = iris.target\n",
    "print(iris_label)\n",
    "print(iris.target_names)\n",
    "\n",
    "#붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size = 0.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=11)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#decision tree 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state = 11)\n",
    "\n",
    "#학습 수행\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "예측 정확도: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))\n",
    "# print(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "keys = iris_data.keys()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n4\n['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n<class 'numpy.ndarray'>\n3\n['setosa' 'versicolor' 'virginica']\n<class 'numpy.ndarray'>\n(150, 4)\n[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]\n<class 'numpy.ndarray'>\n(150,)\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(type(iris_data.feature_names))\n",
    "print(len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print(type(iris_data.target_names))\n",
    "print(len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print(type(iris_data.data))\n",
    "print(iris_data.data.shape)\n",
    "print(iris_data['data'])\n",
    "\n",
    "print(type(iris_data.target))\n",
    "print(iris_data.target.shape)\n",
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.3, random_state = 121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9556\n"
     ]
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)\n",
    "pred = (dt_clf.predict(X_test))\n",
    "print('{0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "#5-fold cross validation\n",
    "kfold = KFold(n_splits = 5)\n",
    "cv_accuracy = []\n",
    "print(features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 1.0 120 30\n1 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29]\n2 0.9667 120 30\n2 [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n 54 55 56 57 58 59]\n3 0.8667 120 30\n3 [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n 84 85 86 87 88 89]\n4 0.9333 120 30\n4 [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119]\n5 0.7333 120 30\n5 [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n 138 139 140 141 142 143 144 145 146 147 148 149]\n0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "\n",
    "    accuracy = np.round(accuracy_score(y_test, pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(n_iter, accuracy, train_size,  test_size)\n",
    "    print(n_iter, test_index)\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print(np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n1    50\n2    50\nName: label, dtype: int64\n0    50\nName: label, dtype: int64\n2\n0    50\n2    50\nName: label, dtype: int64\n1    50\nName: label, dtype: int64\n3\n0    50\n1    50\nName: label, dtype: int64\n2    50\nName: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(n_iter)\n",
    "    print(label_train.value_counts())\n",
    "    print(label_test.value_counts())\n",
    "    iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n2    34\n0    33\n1    33\nName: label, dtype: int64\n0    17\n1    17\n2    16\nName: label, dtype: int64\n2\n1    34\n0    33\n2    33\nName: label, dtype: int64\n0    17\n2    17\n1    16\nName: label, dtype: int64\n3\n0    34\n1    33\n2    33\nName: label, dtype: int64\n1    17\n2    17\n0    16\nName: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(n_iter)\n",
    "    print(label_train.value_counts())\n",
    "    print(label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 0.98 100 50\n1 [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n2 0.94 100 50\n2 [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n3 0.98 100 50\n3 [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n[0.98 0.94 0.98]\n0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(n_iter, accuracy, train_size, test_size)\n",
    "    print(n_iter, test_index)\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print(np.round(cv_accuracy, 4))\n",
    "print(np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.98 0.94 0.98]\n0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print(np.round(scores, 4))\n",
    "print(np.round(np.mean(scores),4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = {'max_depth' : [1,2,3], 'min_samples_split': [2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_test_score</th>\n      <th>rank_test_score</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n      <td>0.700000</td>\n      <td>5</td>\n      <td>0.700</td>\n      <td>0.7</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n      <td>0.700000</td>\n      <td>5</td>\n      <td>0.700</td>\n      <td>0.7</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n      <td>0.958333</td>\n      <td>3</td>\n      <td>0.925</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n      <td>0.958333</td>\n      <td>3</td>\n      <td>0.925</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n      <td>0.975000</td>\n      <td>1</td>\n      <td>0.975</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n      <td>0.975000</td>\n      <td>1</td>\n      <td>0.975</td>\n      <td>1.0</td>\n      <td>0.95</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state = 121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "###refit = True가 default, True면 가장 좋은 파라미터 설정으로 재 학습\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'max_depth': 3, 'min_samples_split': 2}\n0.975\n"
     ]
    }
   ],
   "source": [
    "print(grid_dtree.best_params_)\n",
    "print(grid_dtree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "pred = estimator.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "print(encoder.inverse_transform([4,5,2,0,1,1,3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 1.]\n [0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 1. 0. 0.]\n [0. 0. 1. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0.]]\n(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "\n",
    "labels = labels.reshape(-1,1)\n",
    "\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print(oh_labels.toarray())\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0        1         0        0         0           0         0\n",
       "1        0         1        0         0           0         0\n",
       "2        0         0        0         0           1         0\n",
       "3        0         0        0         0           0         1\n",
       "4        0         0        0         1           0         0\n",
       "5        0         0        0         1           0         0\n",
       "6        0         0        1         0           0         0\n",
       "7        0         0        1         0           0         0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_TV</th>\n      <th>item_냉장고</th>\n      <th>item_믹서</th>\n      <th>item_선풍기</th>\n      <th>item_전자레인지</th>\n      <th>item_컴퓨터</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'item':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sepal length (cm)    5.843333\nsepal width (cm)     3.057333\npetal length (cm)    3.758000\npetal width (cm)     1.199333\ndtype: float64\nsepal length (cm)    0.685694\nsepal width (cm)     0.189979\npetal length (cm)    3.116278\npetal width (cm)     0.581006\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "print(iris_df.mean())\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sepal length (cm)   -1.690315e-15\nsepal width (cm)    -1.842970e-15\npetal length (cm)   -1.698641e-15\npetal width (cm)    -1.409243e-15\ndtype: float64\nsepal length (cm)    1.006711\nsepal width (cm)     1.006711\npetal length (cm)    1.006711\npetal width (cm)     1.006711\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print(iris_df_scaled.mean())\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sepal length (cm)    0.0\nsepal width (cm)     0.0\npetal length (cm)    0.0\npetal width (cm)     0.0\ndtype: float64\nsepal length (cm)    1.0\nsepal width (cm)     1.0\npetal length (cm)    1.0\npetal width (cm)     1.0\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print(iris_df_scaled.min())\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 타이타닉 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}